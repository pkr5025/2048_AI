{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import logcosh\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(1)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class board():\n",
    "    score =0\n",
    "    lose = 0\n",
    "    tile = 2\n",
    "    def __init__(self):\n",
    "        self.grid = np.array([np.zeros(4) for i in range(4)])\n",
    "        i = np.random.randint(4)\n",
    "        j = np.random.randint(4)\n",
    "        self.grid[i,j] = 2\n",
    "        k,l = i,j\n",
    "\n",
    "        while(i==k and l==j):\n",
    "            k = np.random.randint(4)\n",
    "            l = np.random.randint(4)\n",
    "        self.grid[k,l] = 2\n",
    "\n",
    "### Shift, merge, and move constitute one move ###        \n",
    "    def shift(self):\n",
    "        current = np.array([np.zeros(4) for i in range(4)])\n",
    "        for i in range(4):\n",
    "            position = 0\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] != 0:\n",
    "                    current[i][position] = self.grid[i][j]\n",
    "                    position+=1\n",
    "        self.grid = current\n",
    "    def merge(self):\n",
    "        #shift left, merge values, shift left\n",
    "        self.shift()\n",
    "        for i in range(4):\n",
    "            for j in range(3):\n",
    "                if self.grid[i][j] == self.grid[i][j+1] and self.grid[i][j] != 0:\n",
    "                    self.grid[i][j] *= 2\n",
    "                    self.score+= self.grid[i][j]\n",
    "                    if (self.grid[i][j]) > self.tile:\n",
    "                        self.tile = self.grid[i][j]\n",
    "                    self.grid[i][j+1] = 0\n",
    "        self.shift()\n",
    "        \n",
    "    def move(self, direction):\n",
    "        #Merge everything left.  Use flip and transpose for other orientations\n",
    "        self.temp = copy.deepcopy(self.grid)\n",
    "        if direction == 'u':\n",
    "            self.grid = np.transpose(self.grid)\n",
    "            self.merge()\n",
    "            self.grid = np.transpose(self.grid)\n",
    "        elif direction == 'd':\n",
    "            self.grid = np.flip(np.transpose(self.grid),1)\n",
    "            self.merge()\n",
    "            self.grid = np.transpose(np.flip(self.grid,1))\n",
    "        elif direction == 'r':\n",
    "            self.grid = np.flip(self.grid)\n",
    "            self.merge()\n",
    "            self.grid = np.flip(self.grid)\n",
    "        else:\n",
    "            self.merge()\n",
    "        \n",
    "### Check if the player has lost ###\n",
    "    def lost(self):\n",
    "        self.lose = 1\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] == 0:\n",
    "                    self.lose = 0 #Haven't lost yet\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                try:\n",
    "                    if (self.grid[i][j] == self.grid[i+1][j]):\n",
    "                        self.lose = 0\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    if (self.grid[i][j] == self.grid[i][j+1]):\n",
    "                        self.lose = 0\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "    def add_tile(self):\n",
    "        possibilities = []\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if self.grid[i][j] == 0:\n",
    "                    possibilities.append((i,j))\n",
    "        value = np.random.choice([2,4], p=(.9,.1))\n",
    "        if possibilities:\n",
    "            a=possibilities[np.random.choice(len(possibilities))]\n",
    "            self.grid[a] = value\n",
    "    def legal_move(self):\n",
    "        score = self.score\n",
    "        legal_moves = []\n",
    "        temp_grid = self.grid\n",
    "        self.move('l')\n",
    "        if (not np.array_equal(self.grid,temp_grid)):\n",
    "            legal_moves.append('l')\n",
    "        self.grid = temp_grid\n",
    "        self.move('r')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('r')\n",
    "        self.grid = temp_grid\n",
    "        self.move('u')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('u')\n",
    "        self.grid = temp_grid\n",
    "        self.move('d')\n",
    "        if (not np.array_equal(self.grid, temp_grid)):\n",
    "            legal_moves.append('d')\n",
    "        self.grid = temp_grid\n",
    "        self.score = score\n",
    "        return legal_moves\n",
    "            \n",
    "    def random_game(self):\n",
    "        states = []\n",
    "        while (not self.lose):\n",
    "            move = np.random.choice(['l','r','u','d'])\n",
    "            states.append((self.grid, move))\n",
    "\n",
    "            self.move(move)\n",
    "            self.lost()\n",
    "            if (not np.array_equal(self.grid, self.temp)):\n",
    "                self.add_tile()\n",
    "#        print(self.grid)\n",
    "#        print(self.score)\n",
    "\n",
    "        return states\n",
    "    def random_game_initial_score(self, depth, initial_move =0):\n",
    "        #first iteration out of loop to get first move\n",
    "        counter = 0\n",
    "        if initial_move == 0:\n",
    "            move = np.random.choice(self.legal_move())\n",
    "            first_move = move\n",
    "        else:\n",
    "            move = initial_move\n",
    "            first_move = initial_move\n",
    "        self.move(move)\n",
    "        self.lost()\n",
    "        if (not np.array_equal(self.grid, self.temp)):\n",
    "            self.add_tile()\n",
    "        self.lost()\n",
    "        while (not self.lose and counter < depth):\n",
    "            counter += 1\n",
    "#             if (not self.legal_move()):\n",
    "#                 print(self.lose)\n",
    "#                 print(self.grid)\n",
    "#                 self.lost()\n",
    "#                 print(self.lose)\n",
    "            move = np.random.choice(self.legal_move())\n",
    "            self.move(move)\n",
    "            self.lost()\n",
    "            if (not np.array_equal(self.grid, self.temp)):\n",
    "                self.add_tile()\n",
    "            self.lost()\n",
    "        return first_move, self.score\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_monte_carlo_new_random(game, depth):\n",
    "    def getmove(game):\n",
    "        grids = []\n",
    "        possible_moves = game.legal_move()\n",
    "#        print(possible_moves)\n",
    "        for i in range(100):\n",
    "            grids.append(copy.deepcopy(game))\n",
    "        move_scores = defaultdict(list)\n",
    "        i=0\n",
    "        for games in grids:\n",
    "            initial_move, score = games.random_game_initial_score(depth, possible_moves[i])\n",
    "            move_scores[initial_move].append( score)\n",
    "            i+=1\n",
    "            i=i%(len(possible_moves))\n",
    "        score = 0\n",
    "        for key, value in move_scores.items():\n",
    "            print(key,sum(value)/len(value))\n",
    "            if (sum(value)/len(value) >score ):\n",
    "                    move = key\n",
    "                    score = sum(value)/len(value)\n",
    "        print(move, score)\n",
    "        return move\n",
    "            \n",
    "\n",
    "    states = []\n",
    "    while (not game.lose):\n",
    "        move = getmove(game)\n",
    "        print(game.grid)\n",
    "        #states.append((game.grid, move))\n",
    "        game.move(move)\n",
    "        game.lost()\n",
    "        if (not np.array_equal(game.temp, game.grid)):\n",
    "            game.add_tile()\n",
    "        game.lost()\n",
    "#    print(game.grid)\n",
    "    print(game.score)\n",
    "    print(game.tile)\n",
    "    #return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN():\n",
    "    def __init__(self, game):\n",
    "        self.gamma = 0.99\n",
    "        self.short_memory = np.array([])\n",
    "        self.learning_rate = 0.005\n",
    "        self.game = game\n",
    "        self.epsilon = 0\n",
    "        self.memory = []\n",
    "        self.model = self.buildmodel()\n",
    "    def buildmodel(self, weights=None):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, activation='relu', input_dim = 16))\n",
    "        model.add(Dropout(0.15))\n",
    "#        model.add(Dense(output_dim=120, activation='relu'))\n",
    "#         model.add(Dropout(0.15))\n",
    "#         model.add(Dense(output_dim=120, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        opt = Adam(lr=self.learning_rate)\n",
    "        loss = tf.losses.huber_loss\n",
    "        model.compile(loss=loss, optimizer=opt)\n",
    "        \n",
    "\n",
    "        print(\"Successfully built model\")\n",
    "        return model\n",
    "\n",
    "        if weights:\n",
    "            model.load_weights(weights)\n",
    "        return model\n",
    "    def get_state(self):\n",
    "        return self.game.grid.reshape(1,16)\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def replay_new(self, memory):\n",
    "        if len(memory) > 1000:\n",
    "            minibatch = random.sample(memory, 1000)\n",
    "        else:\n",
    "            minibatch = memory\n",
    "        for state, action, reward, next_state, lost in minibatch:\n",
    "            pred_move = self.model.predict(state)\n",
    "            pred_next_move = self.model.predict(next_state)\n",
    "            target = reward\n",
    "\n",
    "            if not lost:\n",
    "                target = reward + self.gamma * np.max(pred_next_move[0])\n",
    "            pred_move[0][action] = target\n",
    "            \n",
    "            self.model.fit(state, pred_move, epochs=10, verbose=0)\n",
    "    def train_short_memory(self, state, action, reward, next_state, lost, games_counter):\n",
    "        pred_move = self.model.predict(state)\n",
    "        pred_next_move = self.model.predict(next_state)\n",
    "        target = reward\n",
    "\n",
    "        if not lost:\n",
    "            target = reward + self.gamma * np.max(pred_next_move[0])\n",
    "        pred_move[0][action] = target\n",
    "            \n",
    "        self.model.fit(state, pred_move, epochs=10, verbose=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_move(i):\n",
    "    if i == 0:\n",
    "        return 'l'\n",
    "    if i ==1:\n",
    "        return 'r'\n",
    "    if i == 2:\n",
    "        return 'u'\n",
    "    if i == 3:\n",
    "        return 'd'\n",
    "def move_to_int(i):\n",
    "    if i=='l':\n",
    "        return 0\n",
    "    if i == 'r':\n",
    "        return 1\n",
    "    if i == 'u':\n",
    "        return 2\n",
    "    if i == 'd':\n",
    "        return 3\n",
    "def run(dqn):\n",
    "    games_counter = 0\n",
    "    score_plot = []\n",
    "    counter_plot = []\n",
    "    record = 0\n",
    "    while games_counter < 3000:\n",
    "        dqn.game = board()\n",
    "        while not dqn.game.lose:\n",
    "            dqn.epsilon = 188*(.97**games_counter)\n",
    "            \n",
    "            state_old = dqn.get_state()\n",
    "            prev_score = dqn.game.score\n",
    "            if np.random.randint(0,200)< dqn.epsilon:\n",
    "                legal_moves = dqn.game.legal_move()\n",
    "                final_move = np.random.choice(legal_moves)\n",
    "            else:\n",
    "                prediction = dqn.model.predict(state_old.reshape(1,16))\n",
    "                final_move = np.argmax(prediction[0])\n",
    "            final_move = int_to_move(final_move)\n",
    "            temp = copy.deepcopy(dqn.game.grid)\n",
    "\n",
    "#            print(\"+++++++++++++++++++++++++++++++\")\n",
    "#            print(dqn.game.grid, final_move)\n",
    "            dqn.game.move(final_move)\n",
    "            if (not np.array_equal(temp, dqn.game.grid)):\n",
    "                game.add_tile()\n",
    "            dqn.game.add_tile()\n",
    "            final_move = move_to_int(final_move)\n",
    "            state_new = dqn.get_state()\n",
    "            if dqn.game.score == prev_score:\n",
    "                reward = -1\n",
    "            else:\n",
    "                reward = np.log2(dqn.game.score - prev_score)\n",
    "            done = dqn.game.lost()\n",
    "            \n",
    "            if done:\n",
    "                reward -= 1\n",
    "            dqn.train_short_memory(state_old, final_move, reward, state_new, done, games_counter)\n",
    "            \n",
    "            dqn.remember(state_old, final_move, reward, state_new, done)\n",
    "            \n",
    "        dqn.replay_new(dqn.memory)\n",
    "        games_counter +=1\n",
    "        print(\"game\", games_counter, \"score\", dqn.game.score)\n",
    "    dqn.model.save_weights('weights.hdf5')\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
